{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oYM61xrTsP5d"
   },
   "source": [
    "# Retraining an Image Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bL54LWCHt5q5"
   },
   "source": [
    "## 1. 环境配置\n",
    "\n",
    "安装镜像中未安装的 tensorflow_hub 与 pillow，以及我这里出现的错误: *OSError: image file is truncated*，猜测是因为服务器允许的单次数据大小问题，详细讨论见 [Python PIL “IOError: image file truncated” with big images](https://stackoverflow.com/questions/12984426/python-pil-ioerror-image-file-truncated-with-big-images)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -U tensorflow_hub pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dlauq-4FWGZM"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Hub version:\", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mmaHHH7Pvmth"
   },
   "source": [
    "## 2. 模型加载\n",
    "这里是自己手动下载的方式。下载后需要解压。取消下面一行的注释并执行即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tar zxvf ./models/imagenet_mobilenet_v2_140_224_classification_4.tar.gz -C ./models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlsEcKVeuCnf"
   },
   "outputs": [],
   "source": [
    "MODULE_HANDLE = \"./models\"\n",
    "IMAGE_SIZE = (224, 224)\n",
    "print(\"Using {} with input size {}\".format(MODULE_HANDLE, IMAGE_SIZE))\n",
    "\n",
    "BATCH_SIZE = 16 #@param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTY8qzyYv3vl"
   },
   "source": [
    "## 3. 数据集处理\n",
    "\n",
    "将图片缩放裁剪以符合模型输入，以及划分训练验证集、打乱顺序、数据集增强。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBtFK1hO8KsO"
   },
   "outputs": [],
   "source": [
    "data_dir = './datasets'\n",
    "#!ls ./datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "umB5tswsfTEQ"
   },
   "outputs": [],
   "source": [
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)\n",
    "dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,\n",
    "                   interpolation=\"bilinear\")\n",
    "\n",
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    **datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"validation\", shuffle=False, **dataflow_kwargs)\n",
    "\n",
    "do_data_augmentation = True #@param {type:\"boolean\"}\n",
    "if do_data_augmentation:\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        horizontal_flip=True,\n",
    "        width_shift_range=0.2, height_shift_range=0.2,\n",
    "        shear_range=0.2, zoom_range=0.2,\n",
    "        **datagen_kwargs\n",
    "    )\n",
    "else:\n",
    "    train_datagen = valid_datagen\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    data_dir, subset=\"training\", shuffle=True, **dataflow_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FS_gVStowW3G"
   },
   "source": [
    "## 4. 模型定义\n",
    "\n",
    "丢弃原模型的输出层，新建输出层以适应自己数据集的种类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaJW3XrPyFiF"
   },
   "outputs": [],
   "source": [
    "do_fine_tuning = True #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "50FYNIb1dmJH"
   },
   "outputs": [],
   "source": [
    "print(\"Building model with\", MODULE_HANDLE)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(MODULE_HANDLE, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(train_generator.num_classes,\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2e5WupIw2N2"
   },
   "source": [
    "## 5. 模型训练\n",
    "\n",
    "### 5.1 优化器\n",
    "\n",
    "此处使用 SGB，随机梯度下降法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9f3yBUvkd_VJ"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(lr=0.005, momentum=0.9), \n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_YKX2Qnfg6x"
   },
   "outputs": [],
   "source": [
    "steps_per_epoch = train_generator.samples // train_generator.batch_size\n",
    "validation_steps = valid_generator.samples // valid_generator.batch_size\n",
    "hist = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=validation_steps).history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 loss、accuracy 曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CYOw0fTO1W4x"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.ylabel(\"Loss (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,2])\n",
    "plt.plot(hist[\"loss\"], label='loss')\n",
    "plt.plot(hist[\"val_loss\"], label='val_loss')\n",
    "plt.legend();\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel(\"Accuracy (training and validation)\")\n",
    "plt.xlabel(\"Training Steps\")\n",
    "plt.ylim([0,1])\n",
    "plt.plot(hist[\"accuracy\"], label='accuracy')\n",
    "plt.plot(hist[\"val_accuracy\"], label='val_accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YCsAsQM1IRvA"
   },
   "source": [
    "### 5.4 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LGvTi69oIc2d"
   },
   "outputs": [],
   "source": [
    "saved_model_path = \"./output/saved_model\"\n",
    "tf.saved_model.save(model, saved_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ScitaPqhKtuW"
   ],
   "name": "TF Hub for TF2: Retraining an image classifier",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
