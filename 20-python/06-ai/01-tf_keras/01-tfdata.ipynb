{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fZ4CvhiLw1S"
   },
   "source": [
    "## 1. 导包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\n",
      "32 32 1 37\n"
     ]
    }
   ],
   "source": [
    "from captcha.image import ImageCaptcha\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "import string\n",
    "characters = string.digits + string.ascii_uppercase\n",
    "width, height, string_len, classes = 32, 32, 1, len(characters) + 1\n",
    "\n",
    "print(characters)\n",
    "print(width, height, string_len, classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFilter\n",
    "\n",
    "\n",
    "class ImageCaptcha_v2(ImageCaptcha):\n",
    "    def __init__(self, width=160, height=60, fonts=None, font_sizes=None, noise_dots_number=1):\n",
    "        super().__init__(width, height, fonts, font_sizes)\n",
    "        self.noise_dots_number = noise_dots_number\n",
    "\n",
    "    def generate_image(self, chars):\n",
    "        \"\"\"Generate the image of the given characters.\n",
    "        :param chars: text to be generated.\n",
    "        \"\"\"\n",
    "        background = self.random_color(238, 255)\n",
    "        noise_color = self.random_color(10, 200, random.randint(100, 150))\n",
    "        font_color = self.random_color(10, 200, random.randint(230, 255))\n",
    "        im = self.create_captcha_image(chars, font_color, background)\n",
    "        self.create_noise_dots(im, noise_color, self.noise_dots_number)\n",
    "        self.create_noise_curve(im, noise_color)\n",
    "        im = im.filter(ImageFilter.SMOOTH)\n",
    "        return im\n",
    "\n",
    "    def random_color(self, start, end, opacity=None):\n",
    "        red = random.randint(start, end)\n",
    "        green = random.randint(start, end)\n",
    "        blue = random.randint(start, end)\n",
    "        if opacity is None:\n",
    "            return (red, green, blue)\n",
    "        return (red, green, blue, opacity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_fn(characters, string_len, width, height, font_sizes=(16, 18, 20, 22), sample_size=1000):\n",
    "    \"\"\"Return a function that takes no arguments and returns a generator.\n",
    "\n",
    "    Args:\n",
    "        characters: 字符集\n",
    "        string_len: 一次结果的字符长度\n",
    "        width, height: 图片验证码的 w, h\n",
    "        font_sizes: 图片验证码中字符的字体大小\n",
    "        sample_size: 数据集大小\n",
    "    \"\"\"\n",
    "    captcha_gen_backend = ImageCaptcha_v2(width=width, height=height, font_sizes=font_sizes)\n",
    "    def generator():\n",
    "        for _ in range(sample_size):\n",
    "            random_str = ''.join([random.choice(characters)\n",
    "                                  for j in range(string_len)])\n",
    "            x = np.array(captcha_gen_backend.generate_image(random_str)) / 255.0\n",
    "            y = np.array([characters.find(x) for x in random_str])\n",
    "            yield x, y\n",
    "    return generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = generator_fn(characters, string_len, width, height, sample_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAD90lEQVR4nK1WTWzbZBh+7abJGHGc2O7apmtQKyBVASEh0yHl1igV9ECkTawXTisXdtiJgThx4pILQhpqNdZy4NClqBVBAqFV2WUEiTbatMtWlyb9zbpWn904cZW/JeZg76sXO24KPLIUOe//+z3v6w/Ukto/DmpJtXwsRTb65ofoH4fFr/9YEVIT4SuMmwMAAJAUBACSLALAUjphFgEA/scehFpS13MCQ7NGG0lB8eRshI8CQJOoTWh5MG6OBIBX+4KMm2tyEeGjS+kEQ7NmUZuIJ2f1CmxS+Be5Y3NJFkevDb0Q4FROT1SWFKS3CEMuy9//+s3mQQYbNyelIKMonpyVZNFSGQcmseUmymwXtjPOJ7eSNwpl2dLG6FGSxXeDofnkjH2hJLbcQJm5x3M7lad1v3tT2dlStraUrXwlb9TWTl5PkGbvLCfGRqIam1vVSmLLn+79KFfzR2oVzjiVRnnu0dzNBzdzhVyxXMTaDM1OhK9gR5fDkytCSuOxZa16AMbN6ZYqUScbEimvNYSVo/vpYvr237f3O/aNBhprcd+N8Sxr1c8AABiqy+fphkrtSX19qnyjUMkDEGuvrZmbg3PUe2Vi0XHGWoDpxZgki1IRAageF1V9hHqFrnql1uf1Xz97nXJRRgPL8zADjyfRPw63vvg5vZoafntkPrMgV/PvdY0sLf9yPvj61QvX3uTe8Lq8li7M7LQcCIf2ww+FfkhOH7LPnNTZP9Ff1IDf62K8LrqVd2ixuMxScntBTa+mDouiiPYReioWxaJaJl0Oxsd5znhaeW9ChI/OJ2eyu0J2V9Ab/rw+EgAuhyeTD38DAGVjr4LkCiq8VOmM+MO0i7b3KyloPSdkd4VsbpUfCsXvzmiTYTwbQi2pkoIe7jz47t63j4X7AKqX4gKewCfhq3Tr/mDcWdZ9HSoowkcZD+elOIZmJVnUNrFD6xfH9Xb5A3uA6tWa39P/0fDE76kFzdJnu/jGRo5bvyKk+OEQ7n48Oftp9HP9kOvVGkE0OpwOlusJ9rw12DsUGA1MJWJjfNRHsYzHOoaWrOZRUtDg+aBRGuGjgUuE4/mrWtjYq3c+86gvjwc+GDg3WKdrX34cW0onIhc+NPKv1Za2fN1eUI8nuWdwoH5U7GP9Lq+L7qQthwvXbrOlm2KQgUuEtmReOTfw2cWvau/UMHm0aTSPj/0MN4FQS+pUIvZ+6KKP4g46DmgnDQDdjW4bm1N9+HSatqndPl64VdjfG8xfyjahrVvyRD1JFqcXY9ld4bQxNJqeHAAADhUUvztj/jTaQCPhMU1tsmNodmJ00n6eW8UAzKIIH8UzacZ/uYSR0AavWw1EO2h5dfy/8A+d0HjFF3f0sAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32 at 0x2733130A700>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = next(gen())\n",
    "print(characters[label[0]])\n",
    "tf.keras.preprocessing.image.array_to_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10\n",
    "batch_size = 5\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (width, height, 3)\n",
    "y_shape = ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "# Prepare model.\n",
    "tf.keras.backend.clear_session()\n",
    "with strategy.scope():\n",
    "    model = tf.keras.applications.VGG16(weights=None, input_shape=x_shape, classes=classes)\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribute.MirroredStrategy 在 tf2.4 中需要设置 AutoShardPolicy.DATA\n",
    "# 否则 Error: Did not find a shardable source, walked to a node which is not a dataset\n",
    "options = tf.data.Options()\n",
    "options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA\n",
    "\n",
    "gen = generator_fn(characters, string_len, width, height, sample_size=sample_size)\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    generator=gen,\n",
    "    # tf2.4 之后将添加 output_signature 参数，未来会遗弃 output_types, output_shapes\n",
    "    output_types=(tf.float32, tf.int32),\n",
    "    output_shapes=(tf.TensorShape(x_shape), tf.TensorShape(y_shape))\n",
    ").with_options(options)\\\n",
    ".batch(batch_size)\\\n",
    ".prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "2/2 [==============================] - 5s 31ms/step - loss: 4.1442\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 4.1350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e504ad3850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train. Do not specify batch size because the dataset takes care of that.\n",
    "model.fit(\n",
    "    dataset,\n",
    "    epochs=epochs,\n",
    "    workers=2,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ctc_tf24.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
