{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多行输出结果\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XPath的使用\n",
    "\n",
    "XPath，全称 XML Path Language，即 XML 路径语言，它是一门在XML文档中查找信息的语言。XPath 最初设计是用来搜寻XML文档的，但是它同样适用于 HTML 文档的搜索。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. XPath常用规则\n",
    "\n",
    "| 表达式 | 描述 |\n",
    "|-------|-----|\n",
    "| nodename | 选取此节点的所有子节点 |\n",
    "| / | 从当前节点选取直接子节点 |\n",
    "| // | 从当前节点选取子孙节点 |\n",
    "| . | 选取当前节点 |\n",
    "| .. | 选取当前节点的父节点 |\n",
    "| @ | 选取属性 |\n",
    "\n",
    "例如:  \n",
    "`//title[@lang=’eng’]`: 选择所有名称为 title，同时属性 lang 的值为 eng 的节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 例子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><div>\n",
      "    <ul>\n",
      "         <li class=\"ite\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "text = '''\n",
    "<div>\n",
    "    <ul>\n",
    "         <li class=\"item-0\"><a href=\"link1.html\">first item</a></li>\n",
    "         <li class=\"item-1\"><a href=\"link2.html\">second item</a></li>\n",
    "         <li class=\"item-inactive\"><a href=\"link3.html\">third item</a></li>\n",
    "         <li class=\"item-1\"><a href=\"link4.html\">fourth item</a></li>\n",
    "         <li class=\"item-0\"><a href=\"link5.html\">fifth item</a>\n",
    "     </ul>\n",
    " </div>\n",
    "'''\n",
    "\n",
    "html = etree.HTML(text)\n",
    "result = etree.tostring(html)\n",
    "print(result.decode('utf-8')[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 在这里我们首先导入了 LXML 库的 etree 模块，然后声明了一段 HTML 文本，调用 HTML 类进行初始化，这样我们就成功构造了一个 XPath 解析对象，注意到 HTML 文本中的最后一个 li 节点是没有闭合的，但是 etree 模块可以对 HTML 文本进行自动修正。调用 tostring() 方法即可输出修正后的 HTML 代码，但是结果是 bytes 类型，再利用 decode() 方法转成 str 类型\n",
    "\n",
    "也可以读取文本文件解析："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.0 Transitional//EN\" \"http://www.w3.org/TR/REC-html40/loose\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = etree.tostring(html)\n",
    "print(result.decode('utf-8')[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 节点选择\n",
    "### 3.1 所有节点\n",
    "用 `//` 开头的 XPath 规则来选取所有符合要求的节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(result):  <class 'list'>\n",
      "result:  [<Element html at 0x1a5e2c10408>, <Element body at 0x1a5e2c10788>, <Element div at 0x1a5e2c107c8>, <Element ul at 0x1a5e2c10808>, <Element li at 0x1a5e2c10848>, <Element a at 0x1a5e2c108c8>, <Element li at 0x1a5e2c10908>, <Element a at 0x1a5e2c10948>, <Element li at 0x1a5e2c10988>, <Element a at 0x1a5e2c10888>, <Element li at 0x1a5e2c109c8>, <Element a at 0x1a5e2c10a08>, <Element li at 0x1a5e2c10a48>, <Element a at 0x1a5e2c10a88>]\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//*')\n",
    "print('type(result): ', type(result))\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取所有`li`节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  [<Element li at 0x1ed0cc4e988>, <Element li at 0x1ed0cc4e9c8>, <Element li at 0x1ed0cc4ea08>, <Element li at 0x1ed0cc4ea48>, <Element li at 0x1ed0cc4ea88>]\n",
      "result[0]:  <Element li at 0x1ed0cc4e988>\n",
      "type(result[0]):  <class 'lxml.etree._Element'>\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li')\n",
    "print('result: ', result)\n",
    "print('result[0]: ', result[0])\n",
    "print('type(result[0]): ', type(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 子节点\n",
    "通过 `/` 或 `//` 即可查找元素的子节点或子孙节点: `/` 是获取直接子节点，`//` 是获取子孙节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result:  [<Element a at 0x1a5e2b25fc8>, <Element a at 0x1a5e2b25188>, <Element a at 0x1a5e2b58208>, <Element a at 0x1a5e2b58c88>, <Element a at 0x1a5e2b58f08>]\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li/a')\n",
    "print('result: ', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处的 / 是选取直接子节点，如果我们要获取所有子孙节点就该使用 // 了，例如我们要获取 ul 节点下的所有子孙 a 节点:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element a at 0x2c98b52e8c8>, <Element a at 0x2c98b52e908>, <Element a at 0x2c98b52e948>, <Element a at 0x2c98b52e988>, <Element a at 0x2c98b52e9c8>]\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//ul//a')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 父节点\n",
    "用 `..` 来获取父节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item-1']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//a[@href=\"link4.html\"]/../@class')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用 `parent::` 来获取节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['item-1']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//a[@href=\"link4.html\"]/parent::*/@class')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 属性匹配\n",
    "在选取的时候我们还可以用 `@` 符号进行属性过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element li at 0x1ed0cc4e908>, <Element li at 0x1ed0cc4e8c8>]\n",
      "type(result[0]):  <class 'lxml.etree._Element'>\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li[@class=\"item-0\"]')\n",
    "print(result)\n",
    "print(\"type(result[0]): \", type(result[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 嵌套匹配: 属性只要是 `<class 'lxml.etree._Element'>` 都可以进行嵌套匹配"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 数据获取\n",
    "### 4.1 文本获取\n",
    "用 XPath 中的 `text()` 方法可以获取节点中的文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first item', 'fifth item']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li[@class=\"item-0\"]/a/text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意一种不推荐的写法:  \n",
    "`'first item'` 其实是 `a` 节点的内容，如果获取 `li` 的子孙节点的文本，那就会获取到 `li` 与 `a` 之间的空格或者换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first item', 'fifth item', '\\r\\n     ']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li[@class=\"item-0\"]//text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意一种错误写法:\n",
    "`'first item'` 其实是 `a` 节点的内容，如果获取 `li` 的直接节点的文本，那就会只能获取到 `li` 与 `a` 之间的空格或者换行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\r\\n     ']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li[@class=\"item-0\"]/text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 属性获取\n",
    "用 `@` 符号获取节点属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['link1.html', 'link2.html', 'link3.html', 'link4.html', 'link5.html']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result = html.xpath('//li/a/@href')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 通过 `@href` 即可获取节点的 `href` 属性，注意此处和属性匹配的方法不同，属性匹配是中括号加属性名和值来限定某个属性，如 `[@href=\"link1.html\"]`，而此处的 `@href` 指的是获取节点的某个属性，二者需要做好区分。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 属性多匹配\n",
    "有时候某些节点的某个属性可能有多个值，例如下面例子中 `HTML` 文本中的 `li` 节点的 `class` 属性有两个值 `li` 和 `li-first`，但是此时如果我们还想用之前的属性匹配获取就无法匹配了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "text = '''\n",
    "<li class=\"li li-first\"><a href=\"link.html\">first item</a></li>\n",
    "'''\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[@class=\"li\"]/a/text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这时如果属性有多个值就需要用 `contains()` 函数了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first item']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "text = '''\n",
    "<li class=\"li li-first\"><a href=\"link.html\">first item</a></li>\n",
    "'''\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[contains(@class, \"li\")]/a/text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 这样我们通过 contains() 方法，第一个参数传入属性名称，第二个参数传入属性值，这样只要此属性包含所传入的属性值就可以完成匹配了。\n",
    "\n",
    "此种选择方式在某个节点的某个属性有多个值的时候经常会用到，如某个节点的 class 属性通常有多个。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 多属性匹配\n",
    "可能需要根据多个属性才能确定一个节点，这是就需要同时匹配多个属性才可以，那么这里可以使用运算符 `and` 来连接，示例如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first item']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "text = '''\n",
    "<li class=\"li li-first\" name=\"item\"><a href=\"link.html\">first item</a></li>\n",
    "'''\n",
    "html = etree.HTML(text)\n",
    "result = html.xpath('//li[contains(@class, \"li\") and @name=\"item\"]/a/text()')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 按顺序选择\n",
    "可以利用中括号传入索引的方法获取特定次序的节点，如第二个节点，或者最后一个节点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['first item']\n",
      "['fifth item']\n",
      "['first item', 'second item']\n",
      "['third item']\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "html = etree.parse('./temp/test.html', etree.HTMLParser())\n",
    "result_1 = html.xpath('//li[1]/a/text()')  # 序号是从1开始数，而不是0\n",
    "print(result_1)\n",
    "result_last = html.xpath('//li[last()]/a/text()')\n",
    "print(result_last)\n",
    "result_pos_12 = html.xpath('//li[position()<3]/a/text()')\n",
    "print(result_pos_12)\n",
    "result_last_2 = html.xpath('//li[last()-2]/a/text()')\n",
    "print(result_last_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这里我们使用了 last()、position() 等函数，XPath 中提供了 100 多个函数，包括存取、数值、字符串、逻辑、节点、序列等处理功能，具体所有的函数作用可以参考：http://www.w3school.com.cn/xpath/xpath_functions.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 例子：\n",
    "使用 `lxml` 库的 `xpath` 解析猫眼电影排行网页"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "获取网页成功!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://maoyan.com/board/4?offset=0'\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print('获取网页成功!')\n",
    "except RequestException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rank': '1', 'img_url': 'http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c', 'name': '霸王别姬', 'actor': '主演：张国荣,张丰毅,巩俐', 'time': '上映时间：1993-01-01(中国香港)', 'score': '9.6'}, {'rank': '2', 'img_url': 'http://p0.meituan.net/movie/54617769d96807e4d81804284ffe2a27239007.jpg@160w_220h_1e_1c', 'name': '罗马假日', 'actor': '主演：格利高里·派克,奥黛丽·赫本,埃迪·艾伯特', 'time': '上映时间：1953-09-02(美国)', 'score': '9.1'}]\n"
     ]
    }
   ],
   "source": [
    "from lxml import etree\n",
    "\n",
    "# response.encoding = 'utf-8'\n",
    "html = etree.HTML(response.text)\n",
    "dl = html.xpath('//dl[@class=\"board-wrapper\"]/dd')\n",
    "# print('boards: ', boards)\n",
    "# print('type(boards): ', type(boards))\n",
    "\n",
    "results = []\n",
    "for dd in dl:\n",
    "    result = {\n",
    "        'rank': dd.xpath('./i/text()')[0],\n",
    "        'img_url': dd.xpath('./a/img[2]/@data-src')[0],\n",
    "        'name': dd.xpath('.//p[@class=\"name\"]/a/text()')[0],\n",
    "        'actor': dd.xpath('.//p[@class=\"star\"]/text()')[0].strip(),\n",
    "        'time': dd.xpath('.//p[@class=\"releasetime\"]/text()')[0],\n",
    "        'score': dd.xpath('.//i[@class=\"integer\"]/text()')[0] +\\\n",
    "            dd.xpath('.//i[@class=\"fraction\"]/text()')[0]\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "print(results[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将上代码优化整理(依照上节):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crawl maoyan complete\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "from lxml import etree\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "def get_one_page(url: str) -> str:\n",
    "    '''requests获取网页源码'''\n",
    "    # 设置浏览器标识user-agent\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) ' +\n",
    "        'AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.75 Safari/537.36'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        return None\n",
    "    except RequestException as e:\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "\n",
    "def parse_one_page(text: str) -> dict:\n",
    "    '''lxml.etree库XPath解析网页数据并提取到字典里'''\n",
    "    html = etree.HTML(text)\n",
    "    items = html.xpath('//dl[@class=\"board-wrapper\"]/dd')\n",
    "    # 保存数据到字典\n",
    "    for item in items:\n",
    "        yield {\n",
    "            'index': item.xpath('./i/text()')[0],\n",
    "            'image_url': item.xpath('./a/img[2]/@data-src')[0],\n",
    "            'name': item.xpath('.//p[@class=\"name\"]/a/text()')[0],\n",
    "            'actor': item.xpath('.//p[@class=\"star\"]/text()')[0].strip(),\n",
    "            'time': item.xpath('.//p[@class=\"releasetime\"]/text()')[0],\n",
    "            'score': item.xpath('.//i[@class=\"integer\"]/text()')[0] +\n",
    "            item.xpath('.//i[@class=\"fraction\"]/text()')[0]\n",
    "        }\n",
    "\n",
    "\n",
    "def write_to_file(content: dict):\n",
    "    '''将网页解析的字典内容保存到json文件里'''\n",
    "    with open('./temp/results.txt', 'a', encoding=\"utf-8\") as f:\n",
    "        # print(type(json.dumps(content)))\n",
    "        f.write(json.dumps(content, indent=2, ensure_ascii=False) + '\\n')\n",
    "\n",
    "\n",
    "def main(offset: int, save_to_file: bool = False):\n",
    "    '''调用上面函数爬取网页'''\n",
    "    url = 'http://maoyan.com/board/4?offset=' + str(offset)\n",
    "    html = get_one_page(url)\n",
    "    for item in parse_one_page(html):\n",
    "        if save_to_file:\n",
    "            write_to_file(item)\n",
    "        else:\n",
    "            print(item)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if os.path.exists('./temp/results.txt'):\n",
    "        os.remove('./temp/results.txt')\n",
    "    main(offset=0, save_to_file=True)\n",
    "    print('\\nCrawl maoyan complete')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
